{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a7430-098d-4c34-85dc-cf3e1e00bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.tools import Tool\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the dataset\n",
    "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
    "\n",
    "# Convert dataset entries into Document objects\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"\\n\".join([\n",
    "            f\"Name: {guest['name']}\",\n",
    "            f\"Relation: {guest['relation']}\",\n",
    "            f\"Description: {guest['description']}\",\n",
    "            f\"Email: {guest['email']}\"\n",
    "        ]),\n",
    "        metadata={\"name\": guest[\"name\"]}\n",
    "    )\n",
    "    for guest in guest_dataset\n",
    "]\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert docs to embeddings\n",
    "corpus = [doc.page_content for doc in docs]\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Define retrieval function\n",
    "def extract_text(query: str) -> str:\n",
    "    \"\"\"Retrieves semantically relevant guest info using sentence-transformers.\"\"\"\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "\n",
    "    # Get top 3 results\n",
    "    top_results = torch.topk(scores, k=3)\n",
    "\n",
    "    if top_results.indices.numel() == 0:\n",
    "        return \"No matching guest information found.\"\n",
    "\n",
    "    return \"\\n\\n\".join([corpus[idx] for idx in top_results.indices])\n",
    "\n",
    "guest_info_tool = Tool(\n",
    "    name=\"guest_info_retriever\",\n",
    "    func=extract_text,\n",
    "    description=\"Retrieves detailed information about gala guests based on their name or relation using semantic similarity.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c75f46-b9d6-4da9-94c2-547a12c06a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Load Keys\n",
    "load_dotenv()\n",
    "serpapi_key = os.getenv(\"SERPAPI_API_KEY\") # https://serpapi.com/\n",
    "hfapi_key = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "@tool\n",
    "def search_tool(query: str) -> str:\n",
    "    \"\"\"Searches the web using SerpAPI and returns the top result snippet.\"\"\"\n",
    "    from langchain_community.utilities import SerpAPIWrapper\n",
    "    search = SerpAPIWrapper()\n",
    "    return search.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44eb8b67-4cea-46dd-96bd-27f2302b6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "import random\n",
    "\n",
    "def get_weather_info(location: str) -> str:\n",
    "    \"\"\"Fetches dummy weather information for a given location.\"\"\"\n",
    "    # Dummy weather data\n",
    "    weather_conditions = [\n",
    "        {\"condition\": \"Rainy\", \"temp_c\": 15},\n",
    "        {\"condition\": \"Clear\", \"temp_c\": 25},\n",
    "        {\"condition\": \"Windy\", \"temp_c\": 20}\n",
    "    ]\n",
    "    # Randomly select a weather condition\n",
    "    data = random.choice(weather_conditions)\n",
    "    return f\"Weather in {location}: {data['condition']}, {data['temp_c']}Â°C\"\n",
    "\n",
    "# Initialize the tool\n",
    "weather_info_tool = Tool(\n",
    "    name=\"get_weather_info\",\n",
    "    func=get_weather_info,\n",
    "    description=\"Fetches dummy weather information for a given location.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04976d0d-76ec-4f43-8f4d-d1b3fe8b5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from huggingface_hub import list_models\n",
    "\n",
    "def get_hub_stats(author: str) -> str:\n",
    "    \"\"\"Fetches the most downloaded model from a specific author on the Hugging Face Hub.\"\"\"\n",
    "    try:\n",
    "        # List models from the specified author, sorted by downloads\n",
    "        models = list(list_models(author=author, sort=\"downloads\", direction=-1, limit=1))\n",
    "\n",
    "        if models:\n",
    "            model = models[0]\n",
    "            return f\"The most downloaded model by {author} is {model.id} with {model.downloads:,} downloads.\"\n",
    "        else:\n",
    "            return f\"No models found for author {author}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching models for {author}: {str(e)}\"\n",
    "\n",
    "# Initialize the tool\n",
    "hub_stats_tool = Tool(\n",
    "    name=\"get_hub_stats\",\n",
    "    func=get_hub_stats,\n",
    "    description=\"Fetches the most downloaded model from a specific author on the Hugging Face Hub.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b4cd754-23a7-4cf6-82ce-32d6b005a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Step 1: Define the LLM from Ollama\n",
    "llm = ChatOllama(model=\"qwen2.5:32b\")\n",
    "\n",
    "# Step 2: Bind tools (if using)\n",
    "chat_with_tools = llm.bind_tools([guest_info_tool, search_tool, weather_info_tool, hub_stats_tool])\n",
    "\n",
    "# Generate the AgentState and Agent graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    return {\n",
    "        \"messages\": [chat_with_tools.invoke(state[\"messages\"])],\n",
    "    }\n",
    "\n",
    "## The graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message requires a tool, route to tools\n",
    "    # Otherwise, provide a direct response\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "alfred = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95049c0c-3673-47ba-8e89-483bb80c2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "It seems there was a bit of confusion as the information retrieved includes people other than Lady Ada Lovelace. However, focusing on her:\n",
      "\n",
      "Lady Ada Lovelace is an esteemed mathematician and often celebrated as the first computer programmer due to her work on Charles Babbage's Analytical Engine. She made significant contributions in the field of mathematics and computing.\n",
      "\n",
      "It appears there was no direct relation mentioned for her in your contacts list, but she is renowned for her pioneering efforts in early computing concepts.\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\": \"Tell me about 'Lady Ada Lovelace'\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8aa8b17-ee71-4915-a896-1c4c8b9e66e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "It seems there was a mix-up in the provided tool response. Let me provide you with accurate information about Lady Ada Lovelace:\n",
      "\n",
      "**Ada Lovelace** (1815-1852) was a British mathematician and writer, widely regarded as the first computer programmer. She is known for her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine. At a time when Babbage's machine was not built, Lovelace wrote notes on the engine, one of which included what is recognized as the first algorithm intended to be processed by a machine. Her vision of the Analytical Engine going beyond mere number-crunching to becoming a general-purpose computing device was far ahead of its time.\n",
      "\n",
      "**Key Facts:**\n",
      "1. **Family Background**: Ada Lovelace was the only legitimate child of the renowned poet George Gordon, Lord Byron, and his wife Anne Isabella, Lady Byron.\n",
      "2. **Education**: Ada received a strong education in mathematics and science at a time when these subjects were not commonly taught to women. She studied under several notable tutors, including the mathematician and logician Augustus De Morgan.\n",
      "3. **Collaboration with Charles Babbage**: In the 1840s, Lovelace met Charles Babbage, who was the inventor of the Analytical Engine. She collaborated with him, gaining an in-depth understanding of his machine.\n",
      "4. **Notes on the Analytical Engine**: Lovelace wrote a set of notes on the Analytical Engine. Her Note G contains what is considered to be the first algorithm intended to be processed by a computer, thus establishing her significance in the history of computing.\n",
      "5. **Vision of the Future**: Lovelace foresaw the potential of computers extending beyond simple calculations to creating music, graphics, and other creative endeavors, which was revolutionary thinking at the time.\n",
      "\n",
      "Ada Lovelace's contributions laid the groundwork for future developments in computing and she is celebrated as a pioneering figure in the field.\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\": \"Tell me about 'Lady Ada Lovelace'\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e5f4e37-904f-400e-9820-4baabcfccfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "It seems there's an issue with accessing the current weather tools directly. However, generally for a fireworks display in Paris tonight, you would want clear skies and minimal wind to ensure safety and visibility. If you can provide me with a date or specific time, I might be able to give you some general advice based on typical weather patterns, but for precise conditions, it's best to check a local weather report or website. Would you like information on typical weather in Paris at this time of year instead?\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\": \"What's the weather like in Paris tonight? Will it be suitable for our fireworks display?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507a9af-dd5b-46bb-9b61-294a2ef43bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = alfred.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather like in Paris tonight?\")]\n",
    "})\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    print(f\"{m.type.upper()}: {m.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b76b9160-11c6-4bca-b0b5-50659144070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's the weather like in Paris tonight? Will it be suitable for our fireworks display?\", additional_kwargs={}, response_metadata={}, id='dc9014b9-6bfd-48aa-aaa0-135134d259af'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-05-24T21:59:19.407778219Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7119692291, 'load_duration': 13563513, 'prompt_eval_count': 361, 'prompt_eval_duration': 2200389100, 'eval_count': 23, 'eval_duration': 4899650996, 'model_name': 'qwen2.5:32b'}, id='run--7c44deb8-a32a-4d6c-aec5-937b2bf2c0ae-0', tool_calls=[{'name': 'get_weather_info', 'args': {'__arg1': 'Paris'}, 'id': '40ba05fb-35d3-4958-8584-4e47bcc00596', 'type': 'tool_call'}], usage_metadata={'input_tokens': 361, 'output_tokens': 23, 'total_tokens': 384}),\n",
       "  ToolMessage(content='Error: get_weather_info is not a valid tool, try one of [guest_info_retriever].', name='get_weather_info', id='2b16b94d-3e55-4ff3-864d-f888b2f3b2a5', tool_call_id='40ba05fb-35d3-4958-8584-4e47bcc00596', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-05-24T21:59:49.881179691Z', 'done': True, 'done_reason': 'stop', 'total_duration': 30470536386, 'load_duration': 10763510, 'prompt_eval_count': 421, 'prompt_eval_duration': 842231003, 'eval_count': 131, 'eval_duration': 29604271685, 'model_name': 'qwen2.5:32b'}, id='run--33949d5e-63d4-440f-903a-10b1556e2b2a-0', tool_calls=[{'name': 'search_tool', 'args': {'query': 'current weather in Paris'}, 'id': '234da639-0a38-401c-bf93-e322e0f1886b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 421, 'output_tokens': 131, 'total_tokens': 552}),\n",
       "  ToolMessage(content='Error: search_tool is not a valid tool, try one of [guest_info_retriever].', name='search_tool', id='97f023e2-c3fe-437a-9c9f-8b1a8839ba25', tool_call_id='234da639-0a38-401c-bf93-e322e0f1886b', status='error'),\n",
       "  AIMessage(content=\"It seems there's an issue with accessing the current weather tools directly. However, generally for a fireworks display in Paris tonight, you would want clear skies and minimal wind to ensure safety and visibility. If you can provide me with a date or specific time, I might be able to give you some general advice based on typical weather patterns, but for precise conditions, it's best to check a local weather report or website. Would you like information on typical weather in Paris at this time of year instead?\", additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-05-24T22:00:14.15840837Z', 'done': True, 'done_reason': 'stop', 'total_duration': 24274280990, 'load_duration': 10666713, 'prompt_eval_count': 480, 'prompt_eval_duration': 859990216, 'eval_count': 101, 'eval_duration': 23377177000, 'model_name': 'qwen2.5:32b'}, id='run--4685f192-ff2f-4735-9dc5-3da958c35414-0', usage_metadata={'input_tokens': 480, 'output_tokens': 101, 'total_tokens': 581})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "539edf90-c1dc-4c66-bfab-c767e27cccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "I'll call the `weather_api_tool` instead.\n",
      "\n",
      "```python\n",
      "import weather_api_tool as wat\n",
      "\n",
      "# Get the current weather in Paris\n",
      "def get_paris_weather():\n",
      "    result = wat.get_weather_info(\"Paris\")\n",
      "    \n",
      "    # Check if it will be suitable for fireworks display (assuming dry and windless conditions)\n",
      "    if 'rain' not in result['conditions'] or result['wind_speed'] < 5:\n",
      "        return \"Yes, the weather is expected to be favorable for your fireworks display tonight.\"\n",
      "    else:\n",
      "        return \"The weather might not be ideal for your fireworks display tonight.\"\n",
      "\n",
      "print(get_paris_weather())\n",
      "```\n",
      "\n",
      "Using this code, I can call the `weather_api_tool` and get a response.\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\": \"What's the weather like in Paris tonight? Will it be suitable for our fireworks display?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de87108a-07d4-4251-9771-761f87b4b39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "I'll use the guest_info_retriever tool to find information about Qwen.\n",
      "\n",
      "Using tool 'guest_info_retriever' with args {'model': 'Qwen'}\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\": \"One of our guests is from Qwen. What can you tell me about their most popular model?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e4a90b-ec54-48ed-b891-25646c82268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "Great, thank you for the information. Based on the tool response, the most popular model by Qwen is **Qwen/Qwen2.5-7B-Instruct**, which has been downloaded 3,123,256 times. This model appears to be one of the most widely used and recognized models developed by Qwen. If your guest is interested in natural language processing or any related field, they might find this model useful for their projects or research. Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\": \"One of our guests is from Qwen. What can you tell me about their most popular model?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d39a3607-215a-4ee5-b777-d002ab1862f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "Based on the information provided by the tool, it seems that Dr. Nikola Tesla is not a known public figure or expert in wireless energy transmission at this time (I'm assuming this is 2023). However, I can suggest possible scenarios:\n",
      "\n",
      "1. You could reach out to experts in the field of wireless energy and ask if they have any knowledge about recent advancements made by someone named Dr. Nikola Tesla.\n",
      "2. If you're interested in learning more about the history of wireless energy transmission, Dr. Nikola Tesla's contributions to this field are well-documented. He developed the concept of alternating current (AC) systems, which revolutionized the way electricity is transmitted over long distances.\n",
      "\n",
      "As for preparing for a conversation with Dr. Nikola Tesla, if you were to imagine him being alive and knowledgeable about recent advancements in wireless energy, here are some potential questions you could ask:\n",
      "\n",
      "* What inspired your latest work on wireless energy transmission?\n",
      "* How does your new system address any challenges or limitations of previous designs?\n",
      "* Can you explain the potential applications and benefits of this technology?\n",
      "\n",
      "Keep in mind that these suggestions assume a hypothetical scenario where Dr. Nikola Tesla is knowledgeable about recent advancements in wireless energy transmission, which may not be the case given his historical contributions to the field.\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\":\"I need to speak with 'Dr. Nikola Tesla' about recent advancements in wireless energy. Can you help me prepare for this conversation?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "121c4a62-d24d-4c62-869d-c53e17eced91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "Now you have some basic information about Dr. Nikola Tesla that you can use during your conversation with him. Keep in mind that he might be a bit eccentric, but he's passionate about his work and eager to share it with others.\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\":\"I need to speak with 'Dr. Nikola Tesla' about recent advancements in wireless energy. Can you help me prepare for this conversation?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3feea57-9e7c-444e-b194-4afa788a70e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "It looks like we were able to retrieve some information about Dr. Nikola Tesla. To better prepare you for your conversation with him, I'd recommend reviewing his recent patent and any relevant research in the field of wireless energy transmission. It might also be helpful to brush up on your knowledge of electromagnetic theory and induction.\n",
      "\n",
      "As a side note, it's interesting that we were able to retrieve information about other notable figures from history as well, such as Marie Curie and Ada Lovelace. If you'd like to reach out to them for any reason, their contact information is available in the retrieval output.\n"
     ]
    }
   ],
   "source": [
    "response = alfred.invoke({\"messages\":\"I need to speak with 'Dr. Nikola Tesla' about recent advancements in wireless energy. Can you help me prepare for this conversation?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb568f-1bbd-4fd2-8be5-ca3c0fb7a016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
