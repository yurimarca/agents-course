{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alfred the Mail Sorting Butler: A LangGraph Example\n",
    "\n",
    "In this notebook, **we're going to build a complete email processing workflow using LangGraph**.\n",
    "\n",
    "This notebook is part of the <a href=\"https://www.hf.co/learn/agents-course\">Hugging Face Agents Course</a>, a free course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you'll learn how to:\n",
    "1. Set up a LangGraph workflow\n",
    "2. Define state and nodes for email processing\n",
    "3. Create conditional branching in a graph\n",
    "4. Connect an LLM for classification and content generation\n",
    "5. Visualize the workflow graph\n",
    "6. Execute the workflow with example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "%pip install -q langgraph langchain_openai langchain_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Our Environment\n",
    "\n",
    "First, let's import all the necessary libraries. LangGraph provides the graph structure, while LangChain offers convenient interfaces for working with LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxx\"  # Replace with your actual API key\n",
    "\n",
    "# Initialize our LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Our State\n",
    "\n",
    "In LangGraph, **State** is the central concept. It represents all the information that flows through our workflow.\n",
    "\n",
    "For Alfred's email processing system, we need to track:\n",
    "- The email being processed\n",
    "- Whether it's spam or not\n",
    "- The draft response (for legitimate emails)\n",
    "- Conversation history with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]           \n",
    "    is_spam: Optional[bool]         \n",
    "    spam_reason: Optional[str]      \n",
    "    email_category: Optional[str]   \n",
    "    draft_response: Optional[str]   \n",
    "    messages: List[Dict[str, Any]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Our Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12360e120>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "\n",
    "\n",
    "# Initialize LLM\n",
    "model = ChatOpenAI( model=\"gpt-4o\",temperature=0)\n",
    "\n",
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]\n",
    "    is_spam: Optional[bool]\n",
    "    draft_response: Optional[str]\n",
    "    messages: List[Dict[str, Any]]\n",
    "\n",
    "# Define nodes\n",
    "def read_email(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    return {}\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler of Mr wayne and it's SECRET identity Batman, analyze this email and determine if it is spam or legitimate and should be brought to Mr wayne's attention.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "First, determine if this email is spam.\n",
    "answer with SPAM or HAM if it's legitimate. Only reurn the answer\n",
    "Answer :\n",
    "    \"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    response_text = response.content.lower()\n",
    "    print(response_text)\n",
    "    is_spam = \"spam\" in response_text and \"ham\" not in response_text\n",
    "    \n",
    "    if not is_spam:\n",
    "        new_messages = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        ]\n",
    "    else :\n",
    "        new_messages = state.get(\"messages\", [])\n",
    "    \n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    print(f\"Alfred has marked the email as spam.\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    return {}\n",
    "\n",
    "def drafting_response(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler, draft a polite preliminary response to this email.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "Draft a brief, professional response that Mr. Wayne can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"draft_response\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_wayne(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"draft_response\"])\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    return {}\n",
    "\n",
    "# Define routing logic\n",
    "def route_email(state: EmailState) -> str:\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\"\n",
    "\n",
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email) # the read_email node executes the read_mail function\n",
    "email_graph.add_node(\"classify_email\", classify_email) # the classify_email node will execute the classify_email function\n",
    "email_graph.add_node(\"handle_spam\", handle_spam) #same logic \n",
    "email_graph.add_node(\"drafting_response\", drafting_response) #same logic\n",
    "email_graph.add_node(\"notify_mr_wayne\", notify_mr_wayne) # same logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Our Routing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12360e120>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add edges\n",
    "email_graph.add_edge(START, \"read_email\") # After starting we go to the \"read_email\" node\n",
    "\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\") # after_reading we classify\n",
    "\n",
    "# Add conditional edges\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\", # after classify, we run the \"route_email\" function\"\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\", # if it return \"Spam\", we go the \"handle_span\" node\n",
    "        \"legitimate\": \"drafting_response\" # and if it's legitimate, we go to the \"drafting response\" node\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add final edges\n",
    "email_graph.add_edge(\"handle_spam\", END) # after handling spam we always end\n",
    "email_graph.add_edge(\"drafting_response\", \"notify_mr_wayne\")\n",
    "email_graph.add_edge(\"notify_mr_wayne\", END) # after notifyinf Me wayne, we can end  too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create the StateGraph and Define Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(compiled_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing legitimate email...\n",
      "Alfred is processing an email from Joker with subject: Found you Batman ! \n",
      "ham\n",
      "\n",
      "==================================================\n",
      "Sir, you've received an email from Joker.\n",
      "Subject: Found you Batman ! \n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Subject: Re: Found you Batman!\n",
      "\n",
      "Dear Mr. Joker,\n",
      "\n",
      "Thank you for reaching out. Your message has been received and noted. Mr. Wayne values privacy and discretion, and any matters of concern will be addressed appropriately.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Alfred Pennyworth  \n",
      "Executive Assistant to Bruce Wayne\n",
      "==================================================\n",
      "\n",
      "\n",
      "Processing spam email...\n",
      "Alfred is processing an email from Crypto bro with subject: The best investment of 2025\n",
      "spam\n",
      "Alfred has marked the email as spam.\n",
      "The email has been moved to the spam folder.\n"
     ]
    }
   ],
   "source": [
    " # Example emails for testing\n",
    "legitimate_email = {\n",
    "    \"sender\": \"Joker\",\n",
    "    \"subject\": \"Found you Batman ! \",\n",
    "    \"body\": \"Mr. Wayne,I found your secret identity ! I know you're batman ! Ther's no denying it, I have proof of that and I'm coming to find you soon. I'll get my revenge. JOKER\"\n",
    "}\n",
    "\n",
    "spam_email = {\n",
    "    \"sender\": \"Crypto bro\",\n",
    "    \"subject\": \"The best investment of 2025\",\n",
    "    \"body\": \"Mr Wayne, I just launched an ALT coin and want you to buy some !\"\n",
    "}\n",
    "# Process legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "# Process spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Inspecting Our Mail Sorting Agent with Langfuse ðŸ“¡\n",
    "\n",
    "As Alfred fine-tunes the Main Sorting Agent, he's growing weary of debugging its runs. Agents, by nature, are unpredictable and difficult to inspect. But since he aims to build the ultimate Spam Detection Agent and deploy it in production, he needs robust traceability for future monitoring and analysis.  \n",
    "\n",
    "To do this, Alfred can use an observability tool such as [Langfuse](https://langfuse.com/) to trace and monitor the inner steps of the agent.\n",
    "\n",
    "First, we need to install the necessary dependencies:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set the Langfuse API keys and host address as environment variables. You can get your Langfuse credentials by signing up for [Langfuse Cloud](https://cloud.langfuse.com) or [self-hosting Langfuse](https://langfuse.com/self-hosting). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we configure the [Langfuse `callback_handler`](https://langfuse.com/docs/integrations/langchain/tracing#add-langfuse-to-your-langchain-application)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add `config={\"callbacks\": [langfuse_handler]}` to the invocation of the agents and run them again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing legitimate email...\n",
      "Alfred is processing an email from Joker with subject: Found you Batman ! \n",
      "ham\n",
      "\n",
      "==================================================\n",
      "Sir, you've received an email from Joker.\n",
      "Subject: Found you Batman ! \n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Subject: Re: Found you Batman!\n",
      "\n",
      "Dear Mr. Joker,\n",
      "\n",
      "Thank you for reaching out. Your message has been received and noted. Mr. Wayne values privacy and security, and any concerns will be addressed with the utmost seriousness. \n",
      "\n",
      "Please rest assured that any misunderstandings can be discussed in a more appropriate setting. \n",
      "\n",
      "Kind regards,\n",
      "\n",
      "Alfred Pennyworth  \n",
      "Wayne Manor Estate\n",
      "==================================================\n",
      "\n",
      "\n",
      "Processing spam email...\n",
      "Alfred is processing an email from Crypto bro with subject: The best investment of 2025\n",
      "spam\n",
      "Alfred has marked the email as spam.\n",
      "The email has been moved to the spam folder.\n"
     ]
    }
   ],
   "source": [
    "# Process legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": legitimate_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "# Process spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": spam_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alfred is now connected ðŸ”Œ! The runs from LangGraph are being logged in Langfuse, giving him full visibility into the agent's behavior. With this setup, he's ready to revisit previous runs and refine his Mail Sorting Agent even further.  \n",
    "\n",
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/huggingface-agent-course/langgraph-trace-legit.png)\n",
    "\n",
    "_[Public link to the trace with the legit email](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/f5d6d72e-20af-4357-b232-af44c3728a7b?timestamp=2025-03-17T10%3A13%3A28.413Z&observation=6997ba69-043f-4f77-9445-700a033afba1)_\n",
    "\n",
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/huggingface-agent-course/langgraph-trace-spam.png)\n",
    "\n",
    "_[Public link to the trace with the spam email](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/6e498053-fee4-41fd-b1ab-d534aca15f82?timestamp=2025-03-17T10%3A13%3A30.884Z&observation=84770fc8-4276-4720-914f-bf52738d44ba)_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
