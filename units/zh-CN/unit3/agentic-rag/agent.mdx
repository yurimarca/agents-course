# åˆ›å»ºä½ çš„ Gala æ™ºèƒ½ä½“

ç°åœ¨æˆ‘ä»¬å·²ç»ä¸º Alfred æ„å»ºäº†æ‰€æœ‰å¿…è¦ç»„ä»¶ï¼Œæ˜¯æ—¶å€™å°†å®ƒä»¬æ•´åˆæˆä¸€ä¸ªå®Œæ•´çš„æ™ºèƒ½ä½“æ¥ååŠ©ä¸¾åŠæˆ‘ä»¬çš„å¥¢åç››ä¼šäº†ã€‚

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠå®¾å®¢ä¿¡æ¯æ£€ç´¢ã€ç½‘ç»œæœç´¢ã€å¤©æ°”ä¿¡æ¯å’Œ Hub ç»Ÿè®¡å·¥å…·æ•´åˆæˆä¸€ä¸ªå¼ºå¤§çš„æ™ºèƒ½ä½“ã€‚

## ç»„è£… Alfredï¼šå®Œæ•´æ™ºèƒ½ä½“

æˆ‘ä»¬ä¸éœ€è¦é‡æ–°å®ç°ä¹‹å‰ç« èŠ‚åˆ›å»ºçš„æ‰€æœ‰å·¥å…·ï¼Œåªéœ€ä»ä¿å­˜çš„tools.pyå’Œretriever.pyæ¨¡å—ä¸­å¯¼å…¥å®ƒä»¬å³å¯ã€‚

<Tip>
å¦‚æœä½ å°šæœªå®ç°è¿™äº›å·¥å…·ï¼Œè¯·è¿”å›<a href="./tools">å·¥å…·</a>å’Œ<a href="./invitees">æ£€ç´¢å™¨</a>ç« èŠ‚è¿›è¡Œå®ç°ï¼Œå¹¶å°†å®ƒä»¬æ·»åŠ åˆ°`tools.py`å’Œ`retriever.py`æ–‡ä»¶ä¸­ã€‚
</Tip>

è®©æˆ‘ä»¬ä»ä¹‹å‰ç« èŠ‚å¯¼å…¥å¿…è¦çš„åº“å’Œå·¥å…·ï¼š

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
#  å¯¼å…¥å¿…è¦çš„åº“
import random
from smolagents import CodeAgent, HfApiModel

# ä»è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥å·¥å…·
from tools import DuckDuckGoSearchTool, WeatherInfoTool, HubStatsTool
from retriever import load_guest_dataset
```

ç°åœ¨è®©æˆ‘ä»¬å°†æ‰€æœ‰å·¥å…·ç»„åˆæˆä¸€ä¸ªæ™ºèƒ½ä½“ï¼š

```python
# åˆå§‹åŒ– Hugging Face æ¨¡å‹
model = HfApiModel()

# åˆå§‹åŒ–ç½‘ç»œæœç´¢å·¥å…·
search_tool = DuckDuckGoSearchTool()

#  åˆå§‹åŒ–å¤©æ°”å·¥å…·
weather_info_tool = WeatherInfoTool()

# åˆå§‹åŒ– Hub ç»Ÿè®¡å·¥å…·
hub_stats_tool = HubStatsTool()

# åŠ è½½å®¾å®¢æ•°æ®é›†å¹¶åˆå§‹åŒ–å®¾å®¢ä¿¡æ¯å·¥å…·
guest_info_tool = load_guest_dataset()

# åˆ›å»ºåŒ…å«æ‰€æœ‰å·¥å…·çš„ Alfred
alfred = CodeAgent(
    tools=[guest_info_tool, weather_info_tool, hub_stats_tool, search_tool], 
    model=model,
    add_base_tools=True,  # æ·»åŠ é¢å¤–çš„åŸºç¡€å·¥å…·
    planning_interval=3    # æ¯ 3 æ­¥å¯ç”¨è§„åˆ’
)
```

</hfoption>
<hfoption id="llama-index">

```python
# å¯¼å…¥å¿…è¦åº“
from llama_index.core.agent.workflow import AgentWorkflow
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI

from tools import search_tool, weather_info_tool, hub_stats_tool
from retriever import guest_info_tool
```

Now, let's combine all these tools into a single agent:

```python
# åˆå§‹åŒ– Hugging Face æ¨¡å‹
llm = HuggingFaceInferenceAPI(model_name="Qwen/Qwen2.5-Coder-32B-Instruct")

# åˆ›å»ºåŒ…å«æ‰€æœ‰å·¥å…·çš„ Alfred
alfred = AgentWorkflow.from_tools_or_functions(
    [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool],
    llm=llm,
)
```

</hfoption>
<hfoption id="langgraph">

```python
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage
from langgraph.prebuilt import ToolNode
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace

from tools import DuckDuckGoSearchRun, weather_info_tool, hub_stats_tool
from retriever import guest_info_tool
```

ç°åœ¨å°†æ‰€æœ‰å·¥å…·æ•´åˆåˆ°å•ä¸€æ™ºèƒ½ä½“ï¼š

```python
# åˆå§‹åŒ–ç½‘ç»œæœç´¢å·¥å…·
search_tool = DuckDuckGoSearchRun()

# ç”ŸæˆåŒ…å«å·¥å…·çš„èŠå¤©æ¥å£
llm = HuggingFaceEndpoint(
    repo_id="Qwen/Qwen2.5-Coder-32B-Instruct",
    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,
)

chat = ChatHuggingFace(llm=llm, verbose=True)
tools = [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool]
chat_with_tools = chat.bind_tools(tools)

# ç”Ÿæˆ AgentState å’Œ Agent å›¾
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]

def assistant(state: AgentState):
    return {
        "messages": [chat_with_tools.invoke(state["messages"])],
    }

##  æ„å»ºæµç¨‹å›¾
builder = StateGraph(AgentState)

# å®šä¹‰èŠ‚ç‚¹ï¼šæ‰§è¡Œå…·ä½“å·¥ä½œ
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# å®šä¹‰è¾¹ï¼šæ§åˆ¶æµç¨‹èµ°å‘
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # å¦‚æœæœ€æ–°æ¶ˆæ¯éœ€è¦å·¥å…·è°ƒç”¨ï¼Œåˆ™è·¯ç”±åˆ° tools èŠ‚ç‚¹
    # å¦åˆ™ç›´æ¥å“åº”
    tools_condition,
)
builder.add_edge("tools", "assistant")
alfred = builder.compile()
```
</hfoption>
</hfoptions>

æ‚¨çš„æ™ºèƒ½ä½“ç°å·²å‡†å¤‡å°±ç»ªï¼

## ä½¿ç”¨ Alfredï¼šç«¯åˆ°ç«¯ç¤ºä¾‹

ç°åœ¨ Alfred å·²é…å¤‡æ‰€æœ‰å¿…è¦å·¥å…·ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä»–å¦‚ä½•ååŠ©å¤„ç†æ™šä¼šä¸­çš„å„ç§ä»»åŠ¡ã€‚

### ç¤ºä¾‹ 1ï¼šæŸ¥æ‰¾å˜‰å®¾ä¿¡æ¯

å±•ç¤º Alfred å¦‚ä½•ååŠ©è·å–å˜‰å®¾ä¿¡æ¯ï¼š

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "Tell me about 'Lady Ada Lovelace'"
response = alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
æ ¹æ®æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼ŒAda Lovelace å¥³å£«æ˜¯ä½å¤‡å—å°Šæ•¬çš„æ•°å­¦å®¶å…¼å¥½å‹ã€‚å¥¹å› åœ¨æ•°å­¦å’Œè®¡ç®—é¢†åŸŸçš„å¼€åˆ›æ€§å·¥ä½œè€Œé—»åï¼Œå¸¸å› å…¶åœ¨ Charles Babbage åˆ†ææœºæ–¹é¢çš„å·¥ä½œè¢«èª‰ä¸ºç¬¬ä¸€ä½è®¡ç®—æœºç¨‹åºå‘˜ã€‚å¥¹çš„ç”µå­é‚®ç®±æ˜¯ ada.lovelace@example.comã€‚
```

</hfoption>
<hfoption id="llama-index">

```python
query = "Tell me about Lady Ada Lovelace. What's her background?"
response = await alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response.response.blocks[0].text)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
Ada Lovelace å¥³å£«æ˜¯è‹±å›½æ•°å­¦å®¶å’Œä½œå®¶ï¼Œä»¥å¥¹åœ¨ Charles Babbage åˆ†ææœºæ–¹é¢çš„å·¥ä½œé—»åã€‚å¥¹æ˜¯ç¬¬ä¸€ä¸ªè®¤è¯†åˆ°è¯¥æœºå™¨å…·æœ‰çº¯è®¡ç®—ä¹‹å¤–åº”ç”¨æ½œåŠ›çš„äººã€‚
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages": "Tell me about 'Lady Ada Lovelace'"})

print("ğŸ© Alfred's Response:")
print(response['messages'][-1].content)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
Ada Lovelaceï¼Œå…¨å Augusta Ada Kingï¼Œæ´›å¤«è±æ–¯ä¼¯çˆµå¤«äººï¼Œæ˜¯è‹±å›½æ•°å­¦å®¶å’Œä½œå®¶ã€‚å‡ºç”Ÿäº 1815 å¹´ 12 æœˆ 10 æ—¥ï¼Œé€ä¸–äº 1852 å¹´ 11 æœˆ 27 æ—¥ï¼Œå¥¹å› åœ¨ Charles Babbage æå‡ºçš„æœºæ¢°é€šç”¨è®¡ç®—æœºåˆ†ææœºæ–¹é¢çš„å·¥ä½œè€Œé—»åã€‚Ada Lovelace è¢«èª‰ä¸ºç¬¬ä¸€ä½è®¡ç®—æœºç¨‹åºå‘˜ï¼Œå› ä¸ºå¥¹äº 1843 å¹´ä¸ºåˆ†ææœºåˆ›å»ºäº†ç¨‹åºã€‚å¥¹è®¤è¯†åˆ°è¯¥æœºå™¨çš„ç”¨é€”ä¸ä»…é™äºè®¡ç®—ï¼Œè¿™ç§è¿œè§åœ¨å½“æ—¶æä¸ºç½•è§ã€‚å¥¹å¯¹è®¡ç®—æœºç§‘å­¦é¢†åŸŸçš„è´¡çŒ®ä¸ºæœªæ¥å‘å±•å¥ å®šäº†åŸºç¡€ã€‚æ¯å¹´åæœˆè®¾ç«‹çš„ Ada Lovelace æ—¥æ­£æ˜¯ä¸ºäº†çºªå¿µå¥¹åœ¨ç§‘æŠ€é¢†åŸŸçš„å¼€åˆ›æ€§å·¥ä½œï¼Œæ¿€åŠ±å¥³æ€§åœ¨ STEM é¢†åŸŸçš„å‘å±•ã€‚
```

</hfoption>
</hfoptions>


### ç¤ºä¾‹ 2ï¼šçƒŸèŠ±å¤©æ°”æ ¸æŸ¥

å±•ç¤º Alfred å¦‚ä½•ååŠ©å¤©æ°”æŸ¥è¯¢ï¼š

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "What's the weather like in Paris tonight? Will it be suitable for our fireworks display?"
response = alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response)
```

é¢„æœŸè¾“å‡ºï¼ˆå­˜åœ¨éšæœºæ€§å·®å¼‚ï¼‰ï¼š
```
ğŸ© Alfred's Response:
å·²ä¸ºæ‚¨æŸ¥è¯¢å·´é»å¤©æ°”ã€‚å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸© 25Â°Cã€‚è¿™æ ·çš„æ¡ä»¶éå¸¸é€‚åˆä»Šæ™šçš„çƒŸèŠ±è¡¨æ¼”ã€‚æ™´æœ—çš„å¤œç©ºå°†ä¸ºå£®è§‚è¡¨æ¼”æä¾›ç»ä½³èƒ½è§åº¦ï¼Œèˆ’é€‚çš„æ¸©åº¦ä¹Ÿèƒ½ç¡®ä¿å®¾å®¢ä»¬æ„‰å¿«äº«å—æˆ·å¤–æ´»åŠ¨ã€‚
```

</hfoption>
<hfoption id="llama-index">

```python
query = "What's the weather like in Paris tonight? Will it be suitable for our fireworks display?"
response = await alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
å·´é»ä»Šå¤œæœ‰é›¨ï¼Œæ°”æ¸© 15Â°Cã€‚è€ƒè™‘åˆ°é™é›¨æƒ…å†µï¼Œå¯èƒ½ä¸é€‚å®œè¿›è¡ŒçƒŸèŠ±è¡¨æ¼”ã€‚
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages": "What's the weather like in Paris tonight? Will it be suitable for our fireworks display?"})

print("ğŸ© Alfred's Response:")
print(response['messages'][-1].content)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
å·´é»ä»Šå¤œæœ‰é›¨ä¸”æ°”æ¸© 15Â°Cï¼Œå¯èƒ½ä¸é€‚å®œæ‚¨çš„çƒŸèŠ±è¡¨æ¼”è®¡åˆ’ã€‚
```
</hfoption>
</hfoptions>

### ç¤ºä¾‹ 3ï¼šç»™ AI ç ”ç©¶è€…ç•™ä¸‹æ·±åˆ»å°è±¡

å±•ç¤º Alfred å¦‚ä½•ååŠ©ä¸ AI ç ”ç©¶è€…äº’åŠ¨ï¼š

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "One of our guests is from Qwen. What can you tell me about their most popular model?"
response = alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
Qwen æœ€å—æ¬¢è¿çš„æ¨¡å‹æ˜¯ Qwen/Qwen2.5-VL-7B-Instructï¼Œä¸‹è½½é‡è¾¾ 3,313,345 æ¬¡ã€‚
```
</hfoption>
<hfoption id="llama-index">

```python
query = "One of our guests is from Google. What can you tell me about their most popular model?"
response = await alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
Hugging Face Hub ä¸Š Google æœ€å—æ¬¢è¿çš„æ¨¡å‹æ˜¯ google/electra-base-discriminatorï¼Œä¸‹è½½é‡è¾¾ 28,546,752 æ¬¡ã€‚
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages": "One of our guests is from Qwen. What can you tell me about their most popular model?"})

print("ğŸ© Alfred's Response:")
print(response['messages'][-1].content)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
Qwen ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹æ˜¯ Qwen/Qwen2.5-VL-7B-Instructï¼Œä¸‹è½½é‡è¾¾ 3,313,345 æ¬¡ã€‚
```
</hfoption>
</hfoptions>

### ç¤ºä¾‹ 4ï¼šç»„åˆå¤šå·¥å…·åº”ç”¨

å±•ç¤º Alfred å¦‚ä½•ååŠ©å‡†å¤‡ä¸ Nikola Tesla åšå£«çš„å¯¹è¯ï¼š


<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "I need to speak with Dr. Nikola Tesla about recent advancements in wireless energy. Can you help me prepare for this conversation?"
response = alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
æˆ‘å·²æ”¶é›†ä¿¡æ¯å¸®åŠ©æ‚¨å‡†å¤‡ä¸ Nikola Tesla åšå£«çš„å¯¹è¯ã€‚

å˜‰å®¾ä¿¡æ¯ï¼š
å§“åï¼šDr. Nikola Tesla
å…³ç³»ï¼šå¤§å­¦æ—¶æœŸçš„è€å‹
æè¿°ï¼šä»–æ˜¯æ‚¨å¤§å­¦æ—¶æœŸçš„è€å‹ï¼Œæœ€è¿‘åˆšè·å¾—æ–°å‹æ— çº¿èƒ½é‡ä¼ è¾“ç³»ç»Ÿçš„ä¸“åˆ©ï¼Œéå¸¸ä¹æ„ä¸æ‚¨è®¨è®ºã€‚è¯·è®°ä½ä»–å¯¹é¸½å­æƒ…æœ‰ç‹¬é’Ÿï¼Œè¿™å¯èƒ½æ˜¯å¾ˆå¥½çš„é—²èŠè¯é¢˜ã€‚
é‚®ç®±ï¼šnikola.tesla@gmail.com

æ— çº¿èƒ½æºæœ€æ–°è¿›å±•ï¼š
æ ¹æ®ç½‘ç»œæœç´¢ï¼Œä»¥ä¸‹æ˜¯æ— çº¿èƒ½é‡ä¼ è¾“é¢†åŸŸçš„æœ€æ–°å‘å±•ï¼š
1. ç ”ç©¶äººå‘˜åœ¨ä½¿ç”¨èšç„¦ç”µç£æ³¢è¿›è¡Œè¿œè·ç¦»æ— çº¿è¾“ç”µæ–¹é¢å–å¾—è¿›å±•
2. å¤šå®¶å…¬å¸æ­£åœ¨å¼€å‘ç”¨äºæ¶ˆè´¹ç”µå­çš„è°æŒ¯æ„Ÿåº”è€¦åˆæŠ€æœ¯ 
3. æ— ç‰©ç†è¿æ¥çš„ç”µåŠ¨æ±½è½¦å……ç”µæ–°åº”ç”¨

å¯¹è¯åˆ‡å…¥ç‚¹ï¼š
1. "æˆ‘å¾ˆæƒ³å¬å¬æ‚¨å…³äºæ— çº¿èƒ½é‡ä¼ è¾“æ–°ä¸“åˆ©çš„æƒ…å†µï¼Œä¸å¤§å­¦æ—¶æœŸçš„åŸå§‹æ¦‚å¿µç›¸æ¯”æœ‰ä½•æ”¹è¿›ï¼Ÿ"
2. "æ‚¨æ˜¯å¦å…³æ³¨è¿‘æœŸæ¶ˆè´¹ç”µå­è°æŒ¯æ„Ÿåº”è€¦åˆæŠ€æœ¯çš„å‘å±•ï¼Ÿå¯¹ä»–ä»¬çš„æ–¹æ³•æœ‰ä½•çœ‹æ³•ï¼Ÿ"
3. "æ‚¨çš„é¸½å­æœ€è¿‘å¥½å—ï¼Ÿæˆ‘è®°å¾—æ‚¨å¯¹å®ƒä»¬ç‰¹åˆ«ç€è¿·"

è¿™äº›å†…å®¹å°†ä¸ºæ‚¨ä¸ Tesla åšå£«çš„å¯¹è¯æä¾›å……è¶³è¯é¢˜ï¼ŒåŒæ—¶å±•ç°æ‚¨å¯¹ä»–å…´è¶£é¢†åŸŸå’Œä¸“ä¸šå‘å±•çš„äº†è§£ã€‚
```

</hfoption>
<hfoption id="llama-index">

```python
query = "I need to speak with Dr. Nikola Tesla about recent advancements in wireless energy. Can you help me prepare for this conversation?"
response = await alfred.run(query)

print("ğŸ© Alfred's Response:")
print(response)
```

é¢„æœŸè¾“å‡ºï¼š

```
ğŸ© Alfred's Response:
ä»¥ä¸‹æ˜¯æ‚¨ä¸ Nikola Tesla åšå£«è®¨è®ºæ— çº¿èƒ½æºæ—¶å¯èƒ½æœ‰ç”¨çš„æœ€æ–°è¿›å±•ï¼š

1. **æ— çº¿ç”µåŠ›ä¼ è¾“çš„è¿›å±•ä¸æŒ‘æˆ˜**ï¼šæœ¬æ–‡è®¨è®ºæ— çº¿ç”µåŠ›ä¼ è¾“ï¼ˆWPTï¼‰ä»ä¼ ç»Ÿæœ‰çº¿æ–¹å¼åˆ°ç°ä»£åº”ç”¨ï¼ˆåŒ…æ‹¬å¤ªç©ºå¤ªé˜³èƒ½ç”µç«™ï¼‰çš„æ¼”å˜ï¼Œé‡ç‚¹ä»‹ç»å¾®æ³¢æŠ€æœ¯çš„åˆæœŸåº”ç”¨åŠå½“å‰ç”µå­è®¾å¤‡å…´èµ·å¸¦æ¥çš„éœ€æ±‚ã€‚

2. **é¢å‘ä½“è¡¨ç”µå­è®¾å¤‡çš„æ— çº¿èƒ½é‡ä¼ è¾“æŠ€æœ¯æ–°è¿›å±•**ï¼šæ¢ç´¢æ— çº¿èƒ½é‡ä¼ è¾“ï¼ˆWETï¼‰ä½œä¸ºæ— ç”µæ± /å¯¼çº¿ä¾›ç”µæ–¹æ¡ˆçš„æ½œåŠ›ï¼Œè®¨è®ºå…¶ä¼˜åŠ¿åŠæ½œåœ¨åº”ç”¨åœºæ™¯ã€‚

3. **æ— çº¿ç”µåŠ›ä¼ è¾“ä¸èƒ½é‡æ”¶é›†ï¼šç°çŠ¶ä¸æœªæ¥è¶‹åŠ¿**ï¼šæ¦‚è¿°æ— çº¿ä¾›èƒ½æ–¹æ³•çš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬èƒ½é‡æ”¶é›†å’Œæ— çº¿è¾“ç”µæŠ€æœ¯ï¼Œå±•ç¤ºå¤šä¸ªå‰æ™¯åº”ç”¨å¹¶æ¢è®¨é¢†åŸŸæœªæ¥è¶‹åŠ¿ã€‚

4. **æ— çº¿ç”µåŠ›ä¼ è¾“ï¼šåº”ç”¨ã€æŒ‘æˆ˜ä¸éšœç¢**
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages":"I need to speak with 'Dr. Nikola Tesla' about recent advancements in wireless energy. Can you help me prepare for this conversation?"})

print("ğŸ© Alfred's Response:")
print(response['messages'][-1].content)
```

é¢„æœŸè¾“å‡ºï¼š

```
æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œä»¥ä¸‹æ˜¯å‡†å¤‡ä¸ 'Dr. Nikola Tesla' è®¨è®ºæ— çº¿èƒ½æºæœ€æ–°è¿›å±•çš„å…³é”®è¦ç‚¹ï¼š
1. **æ— çº¿ç”µåŠ›ä¼ è¾“ (WPT)**ï¼šæ¢è®¨å¦‚ä½•é€šè¿‡æ¶ˆé™¤çº¿ç¼†éœ€æ±‚å¹¶åˆ©ç”¨æ„Ÿåº”å’Œè°æŒ¯è€¦åˆæœºåˆ¶é©æ–°èƒ½é‡ä¼ è¾“
2. **æ— çº¿å……ç”µè¿›å±•**ï¼šå¼ºè°ƒæ•ˆç‡æå‡ã€æ›´å¿«å……ç”µé€Ÿåº¦åŠ Qi/Qi2 è®¤è¯è§£å†³æ–¹æ¡ˆçš„å…´èµ·
3. **5G-Advanced åˆ›æ–°ä¸ NearLink åè®®**ï¼šä½œä¸ºæå‡æ— çº¿ç½‘ç»œé€Ÿåº¦ã€å®‰å…¨æ€§å’Œæ•ˆç‡çš„æŠ€æœ¯ï¼Œå¯æ”¯æŒå…ˆè¿›æ— çº¿èƒ½æºåº”ç”¨
4. **è¾¹ç¼˜ AI/ML**ï¼šè®¨è®ºäººå·¥æ™ºèƒ½å¦‚ä½•ä¾èµ–æ— çº¿ç½‘ç»œå®ç°è¾¹ç¼˜æ™ºèƒ½åŒ–ï¼Œæå‡æ™ºèƒ½å®¶å±…è‡ªåŠ¨åŒ–æ°´å¹³
5. **Matter æ ‡å‡†ä¸å®‰å…¨å¢å¼º**ï¼šä½œä¸ºæ¨åŠ¨ IoT è®¾å¤‡è¿æ¥æ•ˆç‡å’Œå®‰å…¨æ€§æå‡çš„å…³é”®åˆ›æ–°
6. **æ— çº¿å……ç”µæŠ€æœ¯çªç ´**ï¼šåŒ…æ‹¬ä»å·å›½ç«‹å¤§å­¦ç­‰æœºæ„çš„æœ€æ–°ç ”ç©¶æˆæœ
```
</hfoption>
</hfoptions>

## é«˜çº§åŠŸèƒ½ï¼šå¯¹è¯è®°å¿†

ä¸ºäº†è®© Alfred åœ¨æ™šä¼šä¸­æ›´æ™ºèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥å¯ç”¨å¯¹è¯è®°å¿†åŠŸèƒ½ä½¿å…¶è®°ä½å…ˆå‰äº¤æµï¼š

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
# åˆ›å»ºå¸¦è®°å¿†çš„ Alfred
alfred_with_memory = CodeAgent(
    tools=[guest_info_tool, weather_info_tool, hub_stats_tool, search_tool], 
    model=model,
    add_base_tools=True,
    planning_interval=3
)

# é¦–æ¬¡äº¤äº’
response1 = alfred_with_memory.run("Tell me about Lady Ada Lovelace.")
print("ğŸ© Alfred's First Response:")
print(response1)

# äºŒæ¬¡äº¤äº’ï¼ˆå¼•ç”¨é¦–æ¬¡å†…å®¹ï¼‰
response2 = alfred_with_memory.run("What projects is she currently working on?", reset=False)
print("ğŸ© Alfred's Second Response:")
print(response2)
```

</hfoption>
<hfoption id="llama-index">

```python
from llama_index.core.workflow import Context

alfred = AgentWorkflow.from_tools_or_functions(
    [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool],
    llm=llm
)

# è®°å¿†çŠ¶æ€
ctx = Context(alfred)

# é¦–æ¬¡äº¤äº’
response1 = await alfred.run("Tell me about Lady Ada Lovelace.", ctx=ctx)
print("ğŸ© Alfred's First Response:")
print(response1)

# äºŒæ¬¡äº¤äº’ï¼ˆå¼•ç”¨é¦–æ¬¡å†…å®¹ï¼‰
response2 = await alfred.run("What projects is she currently working on?", ctx=ctx)
print("ğŸ© Alfred's Second Response:")
print(response2)
```

</hfoption>
<hfoption id="langgraph">

```python
# é¦–æ¬¡äº¤äº’
response = alfred.invoke({"messages": [HumanMessage(content="Tell me about 'Lady Ada Lovelace'. What's her background and how is she related to me?")]})


print("ğŸ© Alfred's Response:")
print(response['messages'][-1].content)
print()

# äºŒæ¬¡äº¤äº’ï¼ˆå¼•ç”¨é¦–æ¬¡å†…å®¹ï¼‰
response = alfred.invoke({"messages": response["messages"] + [HumanMessage(content="What projects is she currently working on?")]})

print("ğŸ© Alfred's Response:")
print(response['messages'][-1].content)
```

</hfoption>
</hfoptions>

æ³¨æ„åˆ°è¿™ä¸‰ç§æ™ºèƒ½ä½“æ¡†æ¶éƒ½æ²¡æœ‰ç›´æ¥é›†æˆè®°å¿†æ¨¡å—ï¼Œè¿™ç§è®¾è®¡æœ‰ä½•ç‰¹æ®Šè€ƒé‡ï¼ŸğŸ§
* smolagentsï¼šè®°å¿†åœ¨ä¸åŒæ‰§è¡Œå‘¨æœŸä¸­ä¸ä¿ç•™ï¼Œéœ€é€šè¿‡ reset=False æ˜¾å¼å£°æ˜
* LlamaIndex: éœ€æ˜¾å¼æ·»åŠ  context å¯¹è±¡è¿›è¡Œè¿è¡Œå‘¨æœŸå†…çš„è®°å¿†ç®¡ç†
* LangGraph: æä¾›æ£€ç´¢å†å²æ¶ˆæ¯é€‰é¡¹æˆ–ä¸“ç”¨ [MemorySaver](https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-3-adding-memory-to-the-chatbot) ç»„ä»¶

## ç»“è¯­

æ­å–œï¼æ‚¨å·²æˆåŠŸæ„å»º Alfredâ€”â€”é…å¤‡å¤šç§å·¥å…·çš„æ™ºèƒ½ä½“åŠ©æ‰‹ï¼Œå¯ååŠ©ä¸¾åŠæœ¬ä¸–çºªæœ€ç››å¤§çš„æ™šä¼šã€‚Alfred ç°åœ¨èƒ½å¤Ÿï¼š

1. æ£€ç´¢å˜‰å®¾è¯¦ç»†ä¿¡æ¯
2. æ ¸æŸ¥å¤©æ°”æ¡ä»¶è§„åˆ’æˆ·å¤–æ´»åŠ¨
3. æä¾›é¡¶å°– AI å¼€å‘è€…åŠå…¶æ¨¡å‹æ´å¯Ÿ
4. ç½‘ç»œæœç´¢æœ€æ–°èµ„è®¯
5. é€šè¿‡è®°å¿†ç»´æŒå¯¹è¯ä¸Šä¸‹æ–‡

å‡­å€Ÿè¿™äº›èƒ½åŠ›ï¼ŒAlfred å·²å‡†å¤‡å°±ç»ªï¼Œç¡®ä¿æ‚¨çš„æ™šä¼šå–å¾—åœ†æ»¡æˆåŠŸï¼Œé€šè¿‡ä¸ªæ€§åŒ–æœåŠ¡å’Œå®æ—¶ä¿¡æ¯ç»™å®¾å®¢ç•™ä¸‹æ·±åˆ»å°è±¡ã€‚
